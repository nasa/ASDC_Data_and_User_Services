{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8135713-846c-4666-a6f7-2c0b4922a131",
   "metadata": {},
   "source": [
    "# TEMPO UVAI vs DSCOVR (spatial)\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook illustrates a comparison of TEMPO ultra-violet aerosol index (UVAI) against DSCOVR EPIC UVAI. TEMPO_O3TOT_L2_V03 and DSCOVR_EPIC_L2_AER_03 are the data collections used as sources of UVAI.\n",
    "\n",
    "TEMPO and DSCOVR granules are downloaded on-the-fly with [earthaccess](https://earthaccess.readthedocs.io/en/latest/) library, which may need to be installed first.\n",
    "\n",
    "## Dataset Information\n",
    "\n",
    "\"DSCOVR_EPIC_L2_AER_03 is the Deep Space Climate Observatory (DSCOVR) Enhanced Polychromatic Imaging Camera (EPIC) Level 2 UV Aerosol Version 3 data product. Observations for this data product are at 340 and 388 nm and are used to derive near UV (ultraviolet) aerosol properties. The EPIC aerosol retrieval algorithm (EPICAERUV) uses a set of aerosol models to account for the presence of carbonaceous aerosols from biomass burning and wildfires (BIO), desert dust (DST), and sulfate-based (SLF) aerosols. These aerosol models are identical to those assumed in the OMI (Ozone Monitoring Instrument) algorithm (Torres et al., 2007; Jethva and Torres, 2011).\" ([Source](https://asdc.larc.nasa.gov/project/DSCOVR/DSCOVR_EPIC_L2_AER_03))\n",
    "\n",
    "Total ozone Level 2 files provide ozone information at Tropospheric Emissions: Monitoring of Pollution (TEMPO)’s native spatial resolution, ~10 km^2 at the center of the Field of Regard (FOR), for individual granules. Each granule covers the entire North-South TEMPO FOR but only a portion of the East-West FOR.\n",
    "\n",
    "## Table of Contents\n",
    "1. Setup\n",
    "2. Define utility functions for DSCOVR and TEMPO data\n",
    "3. Establish access to Earthdata\n",
    "4. Select timeframe of interest\n",
    "5. Retrieving DSCOVR EPIC granules\n",
    "6. For every DSCOVR EPIC granule, find simultaneous TEMPO granules and re-map DSCOVR EPIC data to geolocations of TEMPO\n",
    "\n",
    "## Notebook's general code outline:\n",
    "- Timeframe of interest is selected by a user.\n",
    "- Searches for DSCOVR EPIC granules withing the TEMPO field of regard (FOR) and within user's timeframe by means of earthaccess library.\n",
    "- After downloading DSCOVR EPIC granules, a loop by these granules DSCOVR L2 AER data searches for TEMPO granules simultaneous with DSCOVR EPIC one.\n",
    "- If such TEMPO granules exist, DSCOVR EPIC UVAI retroevals are interpolated to the positions of the TEMPO pixels. The interpolated values are ritten into a netCDF file along with TEMPO geolocations.\n",
    "- Finally original UVAI from DSCOVR EPIC and TEMPO are plotted along with interpolated DSCOVR EPIC values in the same plot. Output images are written into PNG files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e5a63b-bf77-4d3f-bbb4-781f2d63e6a0",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfc6e7df-e8ca-4f89-8d89-7b600c7d4a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import earthaccess # needed to discover and download TEMPO data\n",
    "import netCDF4 as nc # needed to read TEMPO data\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import platform\n",
    "from subprocess import Popen\n",
    "import shutil\n",
    "\n",
    "from shapely.geometry import Point, Polygon # needed to search a point within a polygon\n",
    "from scipy.interpolate import griddata # needed to interpolate TEMPO data to the point of interest\n",
    "from scipy import stats # needed for linear regression analysis\n",
    "\n",
    "import requests # needed to search for and download Pandora data\n",
    "import codecs # needed to read Pandora data\n",
    "import numpy as np\n",
    "\n",
    "import h5py # needed to read DSCOVR_EPIC_L2_TO3 files\n",
    "import matplotlib.pyplot as plt # needed to plot the resulting time series\n",
    "from urllib.request import urlopen, Request # needed to search for and download Pandora data\n",
    "from pathlib import Path # needed to check whether a needed data file is already downloaded\n",
    "from datetime import datetime, timedelta # needed to work with time in plotting time series\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72213f01-0911-4447-a9f8-b59a74bbb24a",
   "metadata": {},
   "source": [
    "# 2. Define utility functions for DSCOVR and TEMPO data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfee6a50-837f-45cf-952a-deb992d367b1",
   "metadata": {},
   "source": [
    "## 2.1 Function to read DSCOVR AER data files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3790e6c6-4a5c-431b-8046-f4c25da07ec4",
   "metadata": {},
   "source": [
    "function read_epic_l2_AER reads DSCOVR_EPIC_L2_AER product file given by its fname\n",
    "and returns arrays of 2D latitudes, longitudes, UVAI, and AOD along with wavelength\n",
    "along with their fill values and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5addad8-7357-4b4e-b283-d8cb55436c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_epic_l2_AER(fname):\n",
    "\n",
    "  aod_name = '/HDFEOS/SWATHS/Aerosol NearUV Swath/Data Fields/FinalAerosolOpticalDepth'\n",
    "  uvai_name = '/HDFEOS/SWATHS/Aerosol NearUV Swath/Data Fields/UVAerosolIndex'\n",
    "  lat_name = '/HDFEOS/SWATHS/Aerosol NearUV Swath/Geolocation Fields/Latitude'\n",
    "  lon_name = '/HDFEOS/SWATHS/Aerosol NearUV Swath/Geolocation Fields/Longitude'\n",
    "  wl_name = '/HDFEOS/SWATHS/Aerosol NearUV Swath/Data Fields/Wavelength'\n",
    "\n",
    "  try:\n",
    "    f = h5py.File(fname, \"r\" )\n",
    "\n",
    "    item = f[aod_name]\n",
    "    aod2D = np.array(item[:])\n",
    "    fv_aod = item.fillvalue\n",
    "\n",
    "    item = f[uvai_name]\n",
    "    uvai2D = np.array(item[:])\n",
    "    fv_uvai = item.fillvalue\n",
    "\n",
    "    item = f[lat_name]\n",
    "    lat2D = np.array(item[:])\n",
    "    fv_lat = item.fillvalue\n",
    "\n",
    "    item = f[lon_name]\n",
    "    lon2D = np.array(item[:])\n",
    "    fv_lon = item.fillvalue\n",
    "\n",
    "    item = f[wl_name]\n",
    "    wl = np.array(item[:])\n",
    "    fv_wl = item.fillvalue\n",
    "\n",
    "    f.close()\n",
    "\n",
    "# getting time from the granule's filename\n",
    "    fname_split = fname.split('_')\n",
    "    timestamp = fname_split[-2]\n",
    "    yyyy= int(timestamp[0 : 4])\n",
    "    mm = int(timestamp[4 : 6])\n",
    "    dd = int(timestamp[6 : 8])\n",
    "    hh = int(timestamp[8 : 10])\n",
    "    mn = int(timestamp[10 : 12])\n",
    "    ss = int(timestamp[12 : 14])\n",
    "\n",
    "  except:\n",
    "    print(\"Unable to find or read hdf5 input granule file \", fname)\n",
    "    aod2D  = 0.\n",
    "    fv_aod  = 0.\n",
    "    uvai2D  = 0.\n",
    "    fv_uvai  = 0.\n",
    "    lat2D  = 0.\n",
    "    fv_lat  = 0.\n",
    "    lon2D  = 0.\n",
    "    fv_lon  = 0.\n",
    "    wl  = 0.\n",
    "    fv_wl  = 0.\n",
    "    yyyy  = 0.\n",
    "    mm  = 0.\n",
    "    dd  = 0.\n",
    "    hh  = 0.\n",
    "    mn  = 0.\n",
    "    ss  = 0.\n",
    "\n",
    "  return aod2D, fv_aod, uvai2D, fv_uvai, lat2D, fv_lat, lon2D, fv_lon\\\n",
    ", wl, fv_wl, yyyy, mm, dd, hh, mn, ss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a2164a-801c-441c-9923-2251e8f83465",
   "metadata": {},
   "source": [
    "## 2.2 Function to read UV Aerosol Index from TEMPO O3TOT data file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110c9f0b-7622-4fef-bc90-abe53a1bc6d6",
   "metadata": {},
   "source": [
    "function read_TEMPO_O3TOT_L2_UVAI reads the following arrays from the\n",
    "TEMPO L2 O3TOT product TEMPO_O3TOT_L2_V01(2):\n",
    "  vertical_column;\n",
    "  vertical_column_uncertainty;\n",
    "and returns respective fields along with coordinates of the pixels.\n",
    "\n",
    "If one requested variables cannot be read, all returned variables are zeroed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9745a0b2-1d21-4e34-bef2-7e7efe0aa5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_TEMPO_O3TOT_L2_UVAI(fn):\n",
    "\n",
    "  var_name = 'uv_aerosol_index'\n",
    "  var_QF_name = 'quality_flag'\n",
    "\n",
    "  try:\n",
    "    ds = nc.Dataset(fn)\n",
    "\n",
    "    prod = ds.groups['product'] # this opens group product, /product, as prod\n",
    "\n",
    "    var = prod.variables[var_name] # this reads variable column_amount_o3 from prod (group product, /product)\n",
    "    uvai = np.array(var)\n",
    "    uvai_fv = var.getncattr('_FillValue')\n",
    "\n",
    "    var_QF = prod.variables[var_QF_name] # this reads variable column_amount_o3 from prod (group product, /product)\n",
    "    uvai_QF = np.array(var_QF)\n",
    "# there is no fill value for the quality flag.\n",
    "# Once it is available in the next version of the product,\n",
    "# un-comment the line below and add fv_QF to the return line.\n",
    "#    fv_QF = var_QF.getncattr('_FillValue')\n",
    "\n",
    "    geo = ds.groups['geolocation'] # this opens group geolocation, /geolocation, as geo\n",
    "\n",
    "    lat = np.array(geo.variables['latitude']) # this reads variable latitude from geo (geolocation group, /geolocation) into a numpy array\n",
    "    lon = np.array(geo.variables['longitude']) # this reads variable longitude from geo (geolocation group, /geolocation) into a numpy array\n",
    "    fv_geo = geo.variables['latitude'].getncattr('_FillValue')\n",
    "# it appeared that garbage values of latitudes and longitudes in the L2 files\n",
    "# are 9.969209968386869E36 while fill value is -1.2676506E30\n",
    "# (after deeper search it was found that actual value in the file is -1.2676506002282294E30).\n",
    "# For this reason, fv_geo is set to 9.96921E36 to make the code working.\n",
    "# Once the problem is resolved and garbage values of latitudes and longitudes\n",
    "# equal to their fill value, the line below must be removed.\n",
    "    fv_geo = 9.969209968386869E36\n",
    "\n",
    "    time = np.array(geo.variables['time'] )# this reads variable longitude from geo (geolocation group, /geolocation) into a numpy array\n",
    "\n",
    "    ds.close()\n",
    "\n",
    "  except:\n",
    "    print('variable '+var_name+' cannot be read in file '+fn)\n",
    "    lat = 0.\n",
    "    lon = 0.\n",
    "    time = 0.\n",
    "    fv_geo = 0.\n",
    "    uvai = 0.\n",
    "    uvai_QF = 0.\n",
    "    fv_uvai = 0.\n",
    "#    fv_QF = -999\n",
    "    prod_unit = ''\n",
    "\n",
    "  return lat, lon, fv_geo, time, uvai, uvai_QF, uvai_fv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a9dbb8-eecb-4f70-aa6e-78ea084978a9",
   "metadata": {},
   "source": [
    "## 2.3 Function creating TEMPO O3 granule polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18cb4d5d-5f7b-4292-8404-98c48d5ef329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TEMPO_L2_polygon(lat, lon, fv_geo):\n",
    "  nx = lon.shape[0]\n",
    "  ny = lon.shape[1]\n",
    "  print('granule has %3d scanlines by %4d pixels' %(nx, ny))\n",
    "\n",
    "  dpos = np.empty([0,2])\n",
    "\n",
    "  x_ind = np.empty([nx, ny], dtype = int) # creating array in x indices\n",
    "  for ix in range(nx): x_ind[ix, :] = ix # populating array in x indices\n",
    "  y_ind = np.empty([nx, ny], dtype = int)\n",
    "  for iy in range(ny): y_ind[:, iy] = iy # populating array in x indices\n",
    "\n",
    "  mask = (lon[ix, iy] != fv_geo)&(lat[ix, iy] != fv_geo)\n",
    "  if len(lon[mask]) == 0:\n",
    "    print('the granule is empty - no meaningful positions')\n",
    "    return dpos\n",
    "\n",
    "# right boundary\n",
    "  r_m = min(x_ind[mask].flatten())\n",
    "  local_mask = (lon[r_m, :] != fv_geo)&(lat[r_m, :] != fv_geo)\n",
    "  r_b = np.stack((lon[r_m, local_mask], lat[r_m, local_mask])).T\n",
    "\n",
    "# left boundary\n",
    "  l_m = max(x_ind[mask].flatten())\n",
    "  local_mask = (lon[l_m, :] != fv_geo)&(lat[l_m, :] != fv_geo)\n",
    "  l_b = np.stack((lon[l_m, local_mask], lat[l_m, local_mask])).T\n",
    "\n",
    "#top and bottom boundaries\n",
    "  t_b = np.empty([0,2])\n",
    "  b_b = np.empty([0,2])\n",
    "  for ix in range(r_m + 1, l_m):\n",
    "    local_mask = (lon[ix, :] != fv_geo)&(lat[ix, :] != fv_geo)\n",
    "    local_y_ind = y_ind[ix, local_mask]\n",
    "    y_ind_top = min(local_y_ind)\n",
    "    y_ind_bottom = max(local_y_ind)\n",
    "    t_b = np.append(t_b, [[lon[ix, y_ind_top], lat[ix, y_ind_top]]], axis=0)\n",
    "    b_b = np.append(b_b, [[lon[ix, y_ind_bottom], lat[ix, y_ind_bottom]]], axis=0)\n",
    "\n",
    "# combining right, top, left, and bottom boundaries together, going along the combined boundary counterclockwise\n",
    "  dpos = np.append(dpos, r_b[ : :-1, :], axis=0) # this adds right boundary, counterclockwise\n",
    "  dpos = np.append(dpos, t_b, axis=0) # this adds top boundary, counterclockwise\n",
    "  dpos = np.append(dpos, l_b, axis=0) # this adds left boundary, counterclockwise\n",
    "  dpos = np.append(dpos, b_b[ : :-1, :], axis=0) # this adds bottom boundary, counterclockwise\n",
    "\n",
    "  print('polygon shape: ',dpos.shape)\n",
    "\n",
    "  return dpos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31506cd8-eef3-4296-b46b-aa1578892cf7",
   "metadata": {},
   "source": [
    "## 2.4 Function writing DSCOVR EPIC UV Aerosol Index re-mapped to TEMPO granule locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e8e9f4e-e335-4224-8da2-3aced2cf8cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_DSCOVR_TEMPO_UVAI(fname, lat2D, lon2D, uvai2D):\n",
    "#\n",
    "# variables:\n",
    "#   fname    - TEMPO file name, will be used to create output file name\n",
    "#   lat2D    - 2D array of TEMPO latitudes\n",
    "#   lon2D    - 2D array of TEMPO longitudes\n",
    "#   uvai2D   - 2D array of DSCOVR EPIC UVAI re-mapped to TEMPO locations\n",
    "# arrays above shoud be of the same shape\n",
    "\n",
    "  try:\n",
    "\n",
    "    (nx, ny) = lat2D.shape\n",
    "    ncf = nc.Dataset('DSCOVR_UVAI_'+fname, mode='w', format='NETCDF4_CLASSIC')\n",
    "    x_dim = ncf.createDimension('mirror_step', nx) # number of scanlines\n",
    "    y_dim = ncf.createDimension('xtrack', ny) # number of pixels in a scanline\n",
    "\n",
    "    lat = ncf.createVariable('lat', np.float32, ('mirror_step', 'xtrack'))\n",
    "    lat.units = 'degrees_north'\n",
    "    lat.long_name = 'latitude'\n",
    "    lat[:,:] = lat2D\n",
    "\n",
    "    lon = ncf.createVariable('lon', np.float32, ('mirror_step', 'xtrack'))\n",
    "    lon.units = 'degrees_east'\n",
    "    lon.long_name = 'longitude'\n",
    "    lon[:,:] = lon2D\n",
    "\n",
    "    uv_aerosol_index = ncf.createVariable('uv_aerosol_index', np.float32, ('mirror_step', 'xtrack'))\n",
    "    uv_aerosol_index[:,:] = uvai2D\n",
    "\n",
    "    ncf.close()\n",
    "\n",
    "    success = True\n",
    "\n",
    "  except: success = False\n",
    "\n",
    "  return success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8812bd5c-17c9-4f35-a7bc-5c4b7b15cb80",
   "metadata": {},
   "source": [
    "# 3. Establish access to EarthData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a196528-e7ea-43c6-b971-ff4294cd5730",
   "metadata": {},
   "source": [
    "## 3.1. Log in\n",
    "\n",
    "User needs to create an account at https://www.earthdata.nasa.gov/\n",
    "Function earthaccess.login prompts for EarthData login and password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18af31d6-5bbe-4d63-8ffd-0d6f00ae1a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = earthaccess.login(strategy=\"interactive\", persist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850c0349-5e6e-4a7c-a760-c1073350f0ed",
   "metadata": {},
   "source": [
    "## 3.2. Create local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9633232-dd04-4093-ba5e-603309b7a907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved .dodsrc to: /home/jovyan/\n"
     ]
    }
   ],
   "source": [
    "homeDir = os.path.expanduser(\"~\") + os.sep\n",
    "\n",
    "with open(homeDir + '.dodsrc', 'w') as file:\n",
    "    file.write('HTTP.COOKIEJAR={}.urs_cookies\\n'.format(homeDir))\n",
    "    file.write('HTTP.NETRC={}.netrc'.format(homeDir))\n",
    "    file.close()\n",
    "\n",
    "print('Saved .dodsrc to:', homeDir)\n",
    "\n",
    "# Set appropriate permissions for Linux/macOS\n",
    "if platform.system() != \"Windows\":\n",
    "    Popen('chmod og-rw ~/.netrc', shell=True)\n",
    "else:\n",
    "    # Copy dodsrc to working directory in Windows\n",
    "    shutil.copy2(homeDir + '.dodsrc', os.getcwd())\n",
    "    print('Copied .dodsrc to:', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b789afe8-ec9b-4b36-a857-ac997bacc04d",
   "metadata": {},
   "source": [
    "# 4. Select timeframe of interest\n",
    "DSCOVR EPIC granules will be searched within this timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c731ad67-ebe4-44fd-8e70-973701edd6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter period of interest, start and end dates, in the form YYYYMMDD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter start date of interest  20230805\n",
      "enter end date of interest  20230805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 8 5 2023 8 5\n"
     ]
    }
   ],
   "source": [
    "print('enter period of interest, start and end dates, in the form YYYYMMDD')\n",
    "datestamp_ini = input('enter start date of interest ')\n",
    "datestamp_fin = input('enter end date of interest ')\n",
    "\n",
    "start_date = int(datestamp_ini)\n",
    "end_date = int(datestamp_fin)\n",
    "\n",
    "yyyy_ini = start_date//10000\n",
    "mm_ini = (start_date//100 - yyyy_ini*100)\n",
    "dd_ini = (start_date - yyyy_ini*10000 - mm_ini*100)\n",
    "\n",
    "yyyy_fin = end_date//10000\n",
    "mm_fin = (end_date//100 - yyyy_fin*100)\n",
    "dd_fin = (end_date - yyyy_fin*10000 - mm_fin*100)\n",
    "print(yyyy_ini, mm_ini, dd_ini, yyyy_fin, mm_fin, dd_fin)\n",
    "\n",
    "date_start = str('%4.4i-%2.2i-%2.2i 00:00:00' %(yyyy_ini, mm_ini, dd_ini))\n",
    "date_end = str('%4.4i-%2.2i-%2.2i 23:59:59' %(yyyy_fin, mm_fin, dd_fin))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3a54f7-6da7-49ea-ba7e-3f00b31546a1",
   "metadata": {},
   "source": [
    "# 5. Retrieving DSCOVR EPIC granules\n",
    "in the time of interest falling into TEMPO polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a36a24d-a242-483a-9849-2eb7e9edf268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 21\n",
      "total number of DSCOVR EPIC L2_AER granules found for TEMPO FOR \n",
      "within period of interes between 2023-08-05 00:00:00 and 2023-08-05 23:59:59 is 21\n"
     ]
    }
   ],
   "source": [
    "short_name = 'DSCOVR_EPIC_L2_AER' # collection name to search for in the EarthData\n",
    "\n",
    "# polygon below is taken from MMT description of TEMPO_O3TOT_L2,\n",
    "# see https://mmt.earthdata.nasa.gov/collections/C2842849465-LARC_CLOUD\n",
    "# Polygon: (10.0°, -170.0°), (10.0°, -10.0°), (80.0°, -10.0°), (80.0°, -170.0°), (10.0°, -170.0°)\n",
    "\n",
    "bbox = (-170., 10., -10., 80.)\n",
    "\n",
    "FOR_results_EPIC = earthaccess.search_data(short_name = short_name\\\n",
    "                                         , temporal = (date_start, date_end)\\\n",
    "                                         , bounding_box = bbox)\n",
    "\n",
    "n_EPIC = len(FOR_results_EPIC)\n",
    "\n",
    "print('total number of DSCOVR EPIC L2_AER granules found for TEMPO FOR'\\\n",
    "    , '\\nwithin period of interes between', date_start, 'and', date_end, 'is', n_EPIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c5e603-5fb1-416d-aaf4-34895c4425eb",
   "metadata": {},
   "source": [
    "## 5.1. ensuring all discovered granules have download links\n",
    "without this step, those granules crash the call of earthaccess.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75fbdba1-a7bf-4246-8dd6-bac279827957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://asdc.larc.nasa.gov/data/DSCOVR/EPIC/L2_AER_03/2023/08/DSCOVR_EPIC_L2_AER_03_20230805004554_03.he5\n",
      "https://asdc.larc.nasa.gov/data/DSCOVR/EPIC/L2_AER_03/2023/08/DSCOVR_EPIC_L2_AER_03_20230805015122_03.he5\n",
      "https://asdc.larc.nasa.gov/data/DSCOVR/EPIC/L2_AER_03/2023/08/DSCOVR_EPIC_L2_AER_03_20230805025649_03.he5\n",
      "https://asdc.larc.nasa.gov/data/DSCOVR/EPIC/L2_AER_03/2023/08/DSCOVR_EPIC_L2_AER_03_20230805040216_03.he5\n",
      "https://asdc.larc.nasa.gov/data/DSCOVR/EPIC/L2_AER_03/2023/08/DSCOVR_EPIC_L2_AER_03_20230805050743_03.he5\n",
      "https://asdc.larc.nasa.gov/data/DSCOVR/EPIC/L2_AER_03/2023/08/DSCOVR_EPIC_L2_AER_03_20230805071838_03.he5\n",
      "https://asdc.larc.nasa.gov/data/DSCOVR/EPIC/L2_AER_03/2023/08/DSCOVR_EPIC_L2_AER_03_20230805082405_03.he5\n",
      "https://asdc.larc.nasa.gov/data/DSCOVR/EPIC/L2_AER_03/2023/08/DSCOVR_EPIC_L2_AER_03_20230805092932_03.he5\n",
      "https://asdc.larc.nasa.gov/data/DSCOVR/EPIC/L2_AER_03/2023/08/DSCOVR_EPIC_L2_AER_03_20230805103500_03.he5\n",
      "https://asdc.larc.nasa.gov/data/DSCOVR/EPIC/L2_AER_03/2023/08/DSCOVR_EPIC_L2_AER_03_20230805114028_03.he5\n",
      "https://asdc.larc.nasa.gov/data/DSCOVR/EPIC/L2_AER_03/2023/08/DSCOVR_EPIC_L2_AER_03_20230805124555_03.he5\n",
      "https://asdc.larc.nasa.gov/data/DSCOVR/EPIC/L2_AER_03/2023/08/DSCOVR_EPIC_L2_AER_03_20230805135123_03.he5\n",
      "https://asdc.larc.nasa.gov/data/DSCOVR/EPIC/L2_AER_03/2023/08/DSCOVR_EPIC_L2_AER_03_20230805145650_03.he5\n",
      "https://asdc.larc.nasa.gov/data/DSCOVR/EPIC/L2_AER_03/2023/08/DSCOVR_EPIC_L2_AER_03_20230805160217_03.he5\n",
      "https://asdc.larc.nasa.gov/data/DSCOVR/EPIC/L2_AER_03/2023/08/DSCOVR_EPIC_L2_AER_03_20230805170745_03.he5\n",
      "https://asdc.larc.nasa.gov/data/DSCOVR/EPIC/L2_AER_03/2023/08/DSCOVR_EPIC_L2_AER_03_20230805181312_03.he5\n",
      "https://asdc.larc.nasa.gov/data/DSCOVR/EPIC/L2_AER_03/2023/08/DSCOVR_EPIC_L2_AER_03_20230805191839_03.he5\n",
      "https://asdc.larc.nasa.gov/data/DSCOVR/EPIC/L2_AER_03/2023/08/DSCOVR_EPIC_L2_AER_03_20230805202406_03.he5\n",
      "https://asdc.larc.nasa.gov/data/DSCOVR/EPIC/L2_AER_03/2023/08/DSCOVR_EPIC_L2_AER_03_20230805212934_03.he5\n",
      "https://asdc.larc.nasa.gov/data/DSCOVR/EPIC/L2_AER_03/2023/08/DSCOVR_EPIC_L2_AER_03_20230805223501_03.he5\n",
      "https://asdc.larc.nasa.gov/data/DSCOVR/EPIC/L2_AER_03/2023/08/DSCOVR_EPIC_L2_AER_03_20230805234028_03.he5\n"
     ]
    }
   ],
   "source": [
    "granule_links_EPIC = []\n",
    "FOR_results_EPIC_bad = []\n",
    "for result in FOR_results_EPIC:\n",
    "  try:\n",
    "    granule_links_EPIC.append(result['umm']['RelatedUrls'][0]['URL'])\n",
    "  except:\n",
    "    FOR_results_EPIC_bad.append(result)\n",
    "\n",
    "for granule_link in sorted(granule_links_EPIC): print(granule_link)\n",
    "for result in FOR_results_EPIC_bad: FOR_results_EPIC.remove(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd38abd-8fef-40e2-b76d-b10b012b42b4",
   "metadata": {},
   "source": [
    "## 5.2. Download DSCOVR EPIC granules\n",
    "and ensuring all granules have been downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "172d7832-8054-4a9c-bbd2-3e2cc2cfb3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Getting 21 granules, approx download size: 0.0 GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940f236c578a47b9ba2b2052a6cff93f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File DSCOVR_EPIC_L2_AER_03_20230805135123_03.he5 already downloaded\n",
      "File DSCOVR_EPIC_L2_AER_03_20230805004554_03.he5 already downloaded\n",
      "File DSCOVR_EPIC_L2_AER_03_20230805114028_03.he5 already downloaded\n",
      "File DSCOVR_EPIC_L2_AER_03_20230805223501_03.he5 already downloaded\n",
      "File DSCOVR_EPIC_L2_AER_03_20230805170745_03.he5 already downloaded\n",
      "File DSCOVR_EPIC_L2_AER_03_20230805191839_03.he5 already downloaded\n",
      "File DSCOVR_EPIC_L2_AER_03_20230805015122_03.he5 already downloaded\n",
      "File DSCOVR_EPIC_L2_AER_03_20230805145650_03.he5 already downloaded\n",
      "File DSCOVR_EPIC_L2_AER_03_20230805181312_03.he5 already downloaded\n",
      "File DSCOVR_EPIC_L2_AER_03_20230805071838_03.he5 already downloaded\n",
      "File DSCOVR_EPIC_L2_AER_03_20230805212934_03.he5 already downloaded\n",
      "File DSCOVR_EPIC_L2_AER_03_20230805092932_03.he5 already downloaded\n",
      "File DSCOVR_EPIC_L2_AER_03_20230805025649_03.he5 already downloaded\n",
      "File DSCOVR_EPIC_L2_AER_03_20230805082405_03.he5 already downloaded\n",
      "File DSCOVR_EPIC_L2_AER_03_20230805202406_03.he5 already downloaded\n",
      "File DSCOVR_EPIC_L2_AER_03_20230805103500_03.he5 already downloaded\n",
      "File DSCOVR_EPIC_L2_AER_03_20230805050743_03.he5 already downloaded\n",
      "File DSCOVR_EPIC_L2_AER_03_20230805040216_03.he5 already downloaded\n",
      "File DSCOVR_EPIC_L2_AER_03_20230805124555_03.he5 already downloaded\n",
      "File DSCOVR_EPIC_L2_AER_03_20230805234028_03.he5 already downloaded\n",
      "File DSCOVR_EPIC_L2_AER_03_20230805160217_03.he5 already downloaded\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b062a678df43b1a8bf2f69c4daef2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16dffd148d247288ca10851cce47c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "downloaded_files = earthaccess.download(FOR_results_EPIC, local_path='.',)\n",
    "\n",
    "# Checking whether all DSCOVR EPIC data files have been downloaded\n",
    "for granule_link in granule_links_EPIC:\n",
    "  EPIC_fname = granule_link.split('/')[-1]\n",
    "# check if file exists in the local directory\n",
    "  if not os.path.exists(EPIC_fname):\n",
    "    print(EPIC_fname, 'does not exist in local directory')\n",
    "# repeat attempt to download\n",
    "    downloaded_files = earthaccess.download(granule_link,\n",
    "                                            local_path='.')\n",
    "# if file still does not exist in the directory, remove its link from the list of links\n",
    "    if not os.path.exists(EPIC_fname): granule_links_EPIC.remove(granule_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8375210-6d33-475c-984b-79b8aad38542",
   "metadata": {},
   "source": [
    "# 6. For every DSCOVR EPIC granule, find simultaneous TEMPO granules and re-map DSCOVR EPIC data to geolocations of TEMPO\n",
    "write re-mapped DSCOVR EPIC UVAI to a netCDF file\n",
    "and plot the original DSCOVR EPIC and TEMPO along with re-mapped DSCOVR EPIC UVAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38277104-5c8d-481a-babd-01951b138d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSCOVR_EPIC_L2_AER_03_20230805004554_03.he5\n",
      "2023-08-05 00:45:54 2023-08-05 00:41:05 2023-08-05 00:47:41\n",
      "Granules found: 0\n",
      "total number of TEMPO version  V03  granules found \n",
      "within period of interes between 2023-08-05 00:41:05 and 2023-08-05 00:47:41  is 0\n",
      "DSCOVR_EPIC_L2_AER_03_20230805015122_03.he5\n",
      "2023-08-05 01:51:22 2023-08-05 01:46:33 2023-08-05 01:53:09\n",
      "Granules found: 0\n",
      "total number of TEMPO version  V03  granules found \n",
      "within period of interes between 2023-08-05 01:46:33 and 2023-08-05 01:53:09  is 0\n",
      "DSCOVR_EPIC_L2_AER_03_20230805025649_03.he5\n",
      "2023-08-05 02:56:49 2023-08-05 02:52:00 2023-08-05 02:58:36\n",
      "Granules found: 0\n",
      "total number of TEMPO version  V03  granules found \n",
      "within period of interes between 2023-08-05 02:52:00 and 2023-08-05 02:58:36  is 0\n",
      "DSCOVR_EPIC_L2_AER_03_20230805040216_03.he5\n",
      "2023-08-05 04:02:16 2023-08-05 03:57:27 2023-08-05 04:04:03\n",
      "Granules found: 0\n",
      "total number of TEMPO version  V03  granules found \n",
      "within period of interes between 2023-08-05 03:57:27 and 2023-08-05 04:04:03  is 0\n",
      "DSCOVR_EPIC_L2_AER_03_20230805050743_03.he5\n",
      "2023-08-05 05:07:43 2023-08-05 05:02:54 2023-08-05 05:09:30\n",
      "Granules found: 0\n",
      "total number of TEMPO version  V03  granules found \n",
      "within period of interes between 2023-08-05 05:02:54 and 2023-08-05 05:09:30  is 0\n",
      "DSCOVR_EPIC_L2_AER_03_20230805071838_03.he5\n",
      "2023-08-05 07:18:38 2023-08-05 07:13:49 2023-08-05 07:20:25\n",
      "Granules found: 0\n",
      "total number of TEMPO version  V03  granules found \n",
      "within period of interes between 2023-08-05 07:13:49 and 2023-08-05 07:20:25  is 0\n",
      "DSCOVR_EPIC_L2_AER_03_20230805082405_03.he5\n",
      "2023-08-05 08:24:05 2023-08-05 08:19:16 2023-08-05 08:25:52\n",
      "Granules found: 0\n",
      "total number of TEMPO version  V03  granules found \n",
      "within period of interes between 2023-08-05 08:19:16 and 2023-08-05 08:25:52  is 0\n",
      "DSCOVR_EPIC_L2_AER_03_20230805092932_03.he5\n",
      "2023-08-05 09:29:32 2023-08-05 09:24:43 2023-08-05 09:31:19\n",
      "Granules found: 0\n",
      "total number of TEMPO version  V03  granules found \n",
      "within period of interes between 2023-08-05 09:24:43 and 2023-08-05 09:31:19  is 0\n",
      "DSCOVR_EPIC_L2_AER_03_20230805103500_03.he5\n",
      "2023-08-05 10:35:00 2023-08-05 10:30:11 2023-08-05 10:36:47\n",
      "Granules found: 0\n",
      "total number of TEMPO version  V03  granules found \n",
      "within period of interes between 2023-08-05 10:30:11 and 2023-08-05 10:36:47  is 0\n",
      "DSCOVR_EPIC_L2_AER_03_20230805114028_03.he5\n",
      "2023-08-05 11:40:28 2023-08-05 11:35:39 2023-08-05 11:42:15\n",
      "Granules found: 0\n",
      "total number of TEMPO version  V03  granules found \n",
      "within period of interes between 2023-08-05 11:35:39 and 2023-08-05 11:42:15  is 0\n",
      "DSCOVR_EPIC_L2_AER_03_20230805124555_03.he5\n",
      "2023-08-05 12:45:55 2023-08-05 12:41:06 2023-08-05 12:47:42\n",
      "Granules found: 2\n",
      "total number of TEMPO version  V03  granules found \n",
      "within period of interes between 2023-08-05 12:41:06 and 2023-08-05 12:47:42  is 2\n",
      " Getting 2 granules, approx download size: 0.21 GB\n",
      "Accessing cloud dataset using dataset endpoint credentials: https://data.asdc.earthdata.nasa.gov/s3credentials\n",
      "Downloaded: TEMPO_O3TOT_L2_V03_20230805T123711Z_S001G05.nc\n",
      "Downloaded: TEMPO_O3TOT_L2_V03_20230805T124324Z_S001G06.nc\n",
      "granule has 123 scanlines by 2048 pixels\n",
      "polygon shape:  (4338, 2)\n",
      "granule has 123 scanlines by 2048 pixels\n",
      "polygon shape:  (4338, 2)\n",
      "DSCOVR_EPIC_L2_AER_03_20230805135123_03.he5\n",
      "2023-08-05 13:51:23 2023-08-05 13:46:34 2023-08-05 13:53:10\n",
      "Granules found: 2\n",
      "total number of TEMPO version  V03  granules found \n",
      "within period of interes between 2023-08-05 13:46:34 and 2023-08-05 13:53:10  is 2\n",
      " Getting 2 granules, approx download size: 0.2 GB\n",
      "Accessing cloud dataset using dataset endpoint credentials: https://data.asdc.earthdata.nasa.gov/s3credentials\n",
      "Downloaded: TEMPO_O3TOT_L2_V03_20230805T134555Z_S002G06.nc\n",
      "Downloaded: TEMPO_O3TOT_L2_V03_20230805T135208Z_S002G07.nc\n",
      "granule has 123 scanlines by 2048 pixels\n",
      "polygon shape:  (4338, 2)\n",
      "granule has 123 scanlines by 2048 pixels\n",
      "polygon shape:  (4338, 2)\n",
      "DSCOVR_EPIC_L2_AER_03_20230805145650_03.he5\n",
      "2023-08-05 14:56:50 2023-08-05 14:52:01 2023-08-05 14:58:37\n",
      "Granules found: 2\n",
      "total number of TEMPO version  V03  granules found \n",
      "within period of interes between 2023-08-05 14:52:01 and 2023-08-05 14:58:37  is 2\n",
      " Getting 2 granules, approx download size: 0.2 GB\n",
      "Accessing cloud dataset using dataset endpoint credentials: https://data.asdc.earthdata.nasa.gov/s3credentials\n",
      "Downloaded: TEMPO_O3TOT_L2_V03_20230805T144826Z_S003G06.nc\n",
      "Downloaded: TEMPO_O3TOT_L2_V03_20230805T145439Z_S003G07.nc\n",
      "granule has 123 scanlines by 2048 pixels\n",
      "polygon shape:  (4338, 2)\n",
      "granule has 123 scanlines by 2048 pixels\n",
      "polygon shape:  (4338, 2)\n",
      "DSCOVR_EPIC_L2_AER_03_20230805160217_03.he5\n",
      "2023-08-05 16:02:17 2023-08-05 15:57:28 2023-08-05 16:04:04\n",
      "Granules found: 2\n",
      "total number of TEMPO version  V03  granules found \n",
      "within period of interes between 2023-08-05 15:57:28 and 2023-08-05 16:04:04  is 2\n",
      " Getting 2 granules, approx download size: 0.2 GB\n",
      "Accessing cloud dataset using dataset endpoint credentials: https://data.asdc.earthdata.nasa.gov/s3credentials\n",
      "Downloaded: TEMPO_O3TOT_L2_V03_20230805T155710Z_S004G07.nc\n",
      "Downloaded: TEMPO_O3TOT_L2_V03_20230805T160323Z_S004G08.nc\n",
      "granule has 123 scanlines by 2048 pixels\n",
      "polygon shape:  (4338, 2)\n",
      "granule has 123 scanlines by 2048 pixels\n",
      "polygon shape:  (4338, 2)\n",
      "DSCOVR_EPIC_L2_AER_03_20230805170745_03.he5\n",
      "2023-08-05 17:07:45 2023-08-05 17:02:56 2023-08-05 17:09:32\n",
      "Granules found: 2\n",
      "total number of TEMPO version  V03  granules found \n",
      "within period of interes between 2023-08-05 17:02:56 and 2023-08-05 17:09:32  is 2\n",
      " Getting 2 granules, approx download size: 0.21 GB\n",
      "Accessing cloud dataset using dataset endpoint credentials: https://data.asdc.earthdata.nasa.gov/s3credentials\n",
      "Downloaded: TEMPO_O3TOT_L2_V03_20230805T165941Z_S005G07.nc\n",
      "Downloaded: TEMPO_O3TOT_L2_V03_20230805T170554Z_S005G08.nc\n",
      "granule has 123 scanlines by 2048 pixels\n",
      "polygon shape:  (4338, 2)\n",
      "granule has 123 scanlines by 2048 pixels\n",
      "polygon shape:  (4338, 2)\n",
      "DSCOVR_EPIC_L2_AER_03_20230805181312_03.he5\n",
      "2023-08-05 18:13:12 2023-08-05 18:08:23 2023-08-05 18:14:59\n",
      "Granules found: 3\n",
      "total number of TEMPO version  V03  granules found \n",
      "within period of interes between 2023-08-05 18:08:23 and 2023-08-05 18:14:59  is 3\n",
      " Getting 3 granules, approx download size: 0.31 GB\n",
      "Accessing cloud dataset using dataset endpoint credentials: https://data.asdc.earthdata.nasa.gov/s3credentials\n",
      "Downloaded: TEMPO_O3TOT_L2_V03_20230805T180212Z_S006G07.nc\n",
      "Downloaded: TEMPO_O3TOT_L2_V03_20230805T180825Z_S006G08.nc\n",
      "Downloaded: TEMPO_O3TOT_L2_V03_20230805T181438Z_S006G09.nc\n",
      "granule has 123 scanlines by 2048 pixels\n",
      "polygon shape:  (4338, 2)\n",
      "granule has 123 scanlines by 2048 pixels\n",
      "polygon shape:  (4338, 2)\n",
      "granule has 123 scanlines by 2048 pixels\n",
      "polygon shape:  (4338, 2)\n",
      "DSCOVR_EPIC_L2_AER_03_20230805191839_03.he5\n",
      "2023-08-05 19:18:39 2023-08-05 19:13:50 2023-08-05 19:20:26\n",
      "Granules found: 2\n",
      "total number of TEMPO version  V03  granules found \n",
      "within period of interes between 2023-08-05 19:13:50 and 2023-08-05 19:20:26  is 2\n",
      " Getting 2 granules, approx download size: 0.21 GB\n",
      "Accessing cloud dataset using dataset endpoint credentials: https://data.asdc.earthdata.nasa.gov/s3credentials\n",
      "Downloaded: TEMPO_O3TOT_L2_V03_20230805T191056Z_S007G08.nc\n",
      "Downloaded: TEMPO_O3TOT_L2_V03_20230805T191709Z_S007G09.nc\n",
      "granule has 123 scanlines by 2048 pixels\n",
      "polygon shape:  (4338, 2)\n",
      "granule has 123 scanlines by 2048 pixels\n",
      "polygon shape:  (4338, 2)\n",
      "DSCOVR_EPIC_L2_AER_03_20230805202406_03.he5\n",
      "2023-08-05 20:24:06 2023-08-05 20:19:17 2023-08-05 20:25:53\n",
      "Granules found: 3\n",
      "total number of TEMPO version  V03  granules found \n",
      "within period of interes between 2023-08-05 20:19:17 and 2023-08-05 20:25:53  is 3\n",
      " Getting 3 granules, approx download size: 0.31 GB\n",
      "Accessing cloud dataset using dataset endpoint credentials: https://data.asdc.earthdata.nasa.gov/s3credentials\n",
      "Downloaded: TEMPO_O3TOT_L2_V03_20230805T201327Z_S008G08.nc\n",
      "Downloaded: TEMPO_O3TOT_L2_V03_20230805T201940Z_S008G09.nc\n",
      "Downloaded: TEMPO_O3TOT_L2_V03_20230805T202553Z_S008G10.nc\n",
      "granule has 123 scanlines by 2048 pixels\n",
      "polygon shape:  (4338, 2)\n",
      "granule has 123 scanlines by 2048 pixels\n",
      "polygon shape:  (4338, 2)\n",
      "granule has 123 scanlines by 2048 pixels\n",
      "polygon shape:  (4338, 2)\n",
      "DSCOVR_EPIC_L2_AER_03_20230805212934_03.he5\n",
      "2023-08-05 21:29:34 2023-08-05 21:24:45 2023-08-05 21:31:21\n",
      "Granules found: 2\n",
      "total number of TEMPO version  V03  granules found \n",
      "within period of interes between 2023-08-05 21:24:45 and 2023-08-05 21:31:21  is 2\n",
      " Getting 2 granules, approx download size: 0.21 GB\n",
      "Accessing cloud dataset using dataset endpoint credentials: https://data.asdc.earthdata.nasa.gov/s3credentials\n",
      "Downloaded: TEMPO_O3TOT_L2_V03_20230805T212211Z_S009G09.nc\n",
      "Downloaded: TEMPO_O3TOT_L2_V03_20230805T212824Z_S009G10.nc\n",
      "granule has 123 scanlines by 2048 pixels\n",
      "polygon shape:  (4338, 2)\n",
      "granule has 123 scanlines by 2048 pixels\n",
      "polygon shape:  (4338, 2)\n",
      "DSCOVR_EPIC_L2_AER_03_20230805223501_03.he5\n",
      "2023-08-05 22:35:01 2023-08-05 22:30:12 2023-08-05 22:36:48\n",
      "Granules found: 2\n",
      "total number of TEMPO version  V03  granules found \n",
      "within period of interes between 2023-08-05 22:30:12 and 2023-08-05 22:36:48  is 2\n",
      " Getting 2 granules, approx download size: 0.21 GB\n",
      "Accessing cloud dataset using dataset endpoint credentials: https://data.asdc.earthdata.nasa.gov/s3credentials\n",
      "Downloaded: TEMPO_O3TOT_L2_V03_20230805T222442Z_S010G09.nc\n",
      "Downloaded: TEMPO_O3TOT_L2_V03_20230805T223055Z_S010G10.nc\n",
      "granule has 123 scanlines by 2048 pixels\n",
      "polygon shape:  (4338, 2)\n",
      "granule has 123 scanlines by 2048 pixels\n",
      "polygon shape:  (4338, 2)\n",
      "DSCOVR_EPIC_L2_AER_03_20230805234028_03.he5\n",
      "2023-08-05 23:40:28 2023-08-05 23:35:39 2023-08-05 23:42:15\n",
      "Granules found: 1\n",
      "total number of TEMPO version  V03  granules found \n",
      "within period of interes between 2023-08-05 23:35:39 and 2023-08-05 23:42:15  is 1\n",
      " Getting 1 granules, approx download size: 0.1 GB\n",
      "Accessing cloud dataset using dataset endpoint credentials: https://data.asdc.earthdata.nasa.gov/s3credentials\n",
      "Downloaded: TEMPO_O3TOT_L2_V03_20230805T233326Z_S011G10.nc\n",
      "granule has 123 scanlines by 2048 pixels\n",
      "polygon shape:  (4338, 2)\n"
     ]
    }
   ],
   "source": [
    "# Setting TEMPO name constants\n",
    "short_name = 'TEMPO_O3TOT_L2' # collection name to search for in the EarthData\n",
    "version = 'V03' # this is the latest available version as of August 02, 2024\n",
    "\n",
    "# cycle by found DSCOVR EPIC granules\n",
    "for granule_link in sorted(granule_links_EPIC):\n",
    "\n",
    "  last_slash_ind = granule_link.rfind('/')\n",
    "  Dfname = granule_link[last_slash_ind+1 : ]\n",
    "  print(Dfname)\n",
    "\n",
    "  aod2D, fv_aod, uvai2D, fv_uvai, lat2D, fv_lat, lon2D, fv_lon\\\n",
    ", wl, fv_wl, yyyy, mm, dd, hh, mn, ss = read_epic_l2_AER(Dfname)\n",
    "\n",
    "  if isinstance(lat2D, float): continue\n",
    "\n",
    "  timestamp = datetime(yyyy, mm, dd, hh, mn, ss)\n",
    "# it was discovered that actual timespan of an EPIC granule begins 289 s before\n",
    "# the granule timestamp and ends 107 s after it.\n",
    "# This timeframe will be used for search of TEMPO granules\n",
    "  timestamp1 = timestamp + timedelta(seconds = -289)\n",
    "  timestamp2 = timestamp + timedelta(seconds = 107)\n",
    "  print(timestamp, timestamp1, timestamp2)\n",
    "\n",
    "  for attempt in range(2):\n",
    "    try:\n",
    "      results = earthaccess.search_data(short_name = short_name\\\n",
    "                                      , version = version\\\n",
    "                                      , temporal = (timestamp1, timestamp2))\n",
    "      break\n",
    "    except: continue\n",
    "\n",
    "  try: n_gr = len(results)\n",
    "  except: n_gr = 0\n",
    "\n",
    "  print('total number of TEMPO version ', version,' granules found', \\\n",
    "        '\\nwithin period of interes between', timestamp1, 'and', timestamp2,\\\n",
    "        ' is', n_gr)\n",
    "\n",
    "  if n_gr == 0: continue # if no TEMPO granules found within the DSCOVR EPIC timeframe, go to the next EPIC granule\n",
    "\n",
    "# masking out DSCOVR fillvalues\n",
    "  mask = (lat2D != fv_lat)&(lon2D != fv_lon)&(uvai2D != fv_uvai)\n",
    "  points = np.column_stack((lon2D[mask], lat2D[mask]))\n",
    "  ff = uvai2D[mask]\n",
    "\n",
    "  downloaded_files = earthaccess.download(results, local_path='.',)\n",
    "\n",
    "  for r in results:\n",
    "    granule_links = r.data_links()\n",
    "    last_slash_ind = granule_links[0].rfind('/')\n",
    "    Tfname = granule_links[0][last_slash_ind+1 : ]\n",
    "\n",
    "    lat, lon, fv_geo, time, uvai, uvai_QF, uvai_fv\\\n",
    " = read_TEMPO_O3TOT_L2_UVAI(Tfname)\n",
    "\n",
    "    polygon = TEMPO_L2_polygon(lat, lon, fv_geo)\n",
    "    coords_poly = list(polygon)\n",
    "    poly = Polygon(coords_poly)\n",
    "\n",
    "# create arrays in indices to restore 2D array after re-mapping\n",
    "    (nx, ny) = lat.shape\n",
    "    y_ind = np.tile(np.linspace(0,ny,ny, endpoint = False, dtype = int), (nx,1))\n",
    "    x_ind = np.tile(np.linspace(0,nx,nx, endpoint = False, dtype = int), (ny,1))\\\n",
    ".transpose()\n",
    "\n",
    "# masking out fill values of TEMPO lat/lon positions\n",
    "    mask_TEMPO = (lat != fv_geo)&(lon != fv_geo)&(uvai != uvai_fv)\n",
    "    lon1D = lon[mask_TEMPO]\n",
    "    lat1D = lat[mask_TEMPO]\n",
    "    pp = np.column_stack((lon1D, lat1D))\n",
    "\n",
    "    x_ind_m = x_ind[mask_TEMPO]\n",
    "    y_ind_m = y_ind[mask_TEMPO]\n",
    "\n",
    "# masking out DSCOVR UVAI to the ranges of TEMPO granule\n",
    "    min_TEMPO_lon = min(lon1D)\n",
    "    max_TEMPO_lon = max(lon1D)\n",
    "    min_TEMPO_lat = min(lat1D)\n",
    "    max_TEMPO_lat = max(lat1D)\n",
    "\n",
    "    mask_DSCOVR = (uvai2D != fv_uvai)\\\n",
    "                 &(lat2D > min_TEMPO_lat)&(lat2D < max_TEMPO_lat)\\\n",
    "                 &(lon2D > min_TEMPO_lon)&(lon2D < max_TEMPO_lon)\n",
    "    lon1D_DSCOVR = lon2D[mask_DSCOVR]\n",
    "    lat1D_DSCOVR = lat2D[mask_DSCOVR]\n",
    "    uvai1D_DSCOVR = uvai2D[mask_DSCOVR]\n",
    "# number of DSCOVR pixels falling into ranges min_TEMPO_lat < lat2D < max_TEMPO_lat, min_TEMPO_lon < lat2D < max_TEMPO_lon\n",
    "    n_DSCOVR_TEMPO = len(uvai1D_DSCOVR)\n",
    "    if n_DSCOVR_TEMPO == 0:\n",
    "      print('no original DSCOVR pixels within TEMPO granule')\n",
    "      continue\n",
    "\n",
    "    mask_DSCOVR_TEMPO = np.empty(n_DSCOVR_TEMPO, dtype = np.bool_)\n",
    "    for i in range(n_DSCOVR_TEMPO):\n",
    "      pp_DSCOVR = np.array([lon1D_DSCOVR[i], lat1D_DSCOVR[i]])\n",
    "      p = Point(pp_DSCOVR)\n",
    "      mask_DSCOVR_TEMPO[i] = p.within(poly)\n",
    "      \n",
    "    lon1D_DSCOVR_TEMPO = lon1D_DSCOVR[mask_DSCOVR_TEMPO]\n",
    "    lat1D_DSCOVR_TEMPO = lat1D_DSCOVR[mask_DSCOVR_TEMPO]\n",
    "    uvai1D_DSCOVR_TEMPO = uvai1D_DSCOVR[mask_DSCOVR_TEMPO]\n",
    "\n",
    "# line below performs re-mapping\n",
    "    DSCOVR_TEMPO_uvai = griddata(points, ff, pp, method='linear'\\\n",
    ", fill_value=-999., rescale=False)\n",
    "# check whether there are any values within valid range\n",
    "    valid_mask = (DSCOVR_TEMPO_uvai>-30)&(DSCOVR_TEMPO_uvai<30)\n",
    "    if len(DSCOVR_TEMPO_uvai[valid_mask]) == 0:\n",
    "      print('no re-mapped DSCOVR pixels within TEMPO granule')\n",
    "      continue\n",
    "\n",
    "# create and fill 2D arrays to be restored\n",
    "    lat2D_TEMPO = np.empty([nx, ny])\n",
    "    lat2D_TEMPO[:, :] = -999.\n",
    "    lon2D_TEMPO = np.empty([nx, ny])\n",
    "    lon2D_TEMPO[:, :] = -999.\n",
    "    uvai2D_TEMPO = np.empty([nx, ny])\n",
    "    uvai2D_TEMPO[:, :] = -999.\n",
    "\n",
    "# restore 2D arrays\n",
    "    for ix, iy, lon1, lat1, uvai1 in\\\n",
    " zip(x_ind_m, y_ind_m, lon1D, lat1D, DSCOVR_TEMPO_uvai):\n",
    "      lat2D_TEMPO[ix, iy] = lat1\n",
    "      lon2D_TEMPO[ix, iy] = lon1\n",
    "      uvai2D_TEMPO[ix, iy] = uvai1\n",
    "\n",
    "# write restored 2D arrays to a netCDF file\n",
    "    output_success = write_DSCOVR_TEMPO_UVAI(Tfname, lat2D_TEMPO, lon2D_TEMPO, uvai2D_TEMPO)\n",
    "    if not output_success: print('failed to write DSCOVR UVAI re-mapped to TEMPO granule into the output file')\n",
    "\n",
    "# plotting the output comparing TEMPO and DSCOVR EPIC UVAI\n",
    "    fig = plt.figure(figsize=(20, 9), dpi=300, facecolor = None)\n",
    "\n",
    "    proj = ccrs.LambertConformal(central_longitude=(min_TEMPO_lon + max_TEMPO_lon)*.5 # -96.0\n",
    "                               , central_latitude=39.0\n",
    "                               , false_easting=0.0\n",
    "                               , false_northing=0.0\n",
    "                               , standard_parallels=(33, 45)\n",
    "                               , globe=None\n",
    "                               , cutoff=10)\n",
    "    transform=ccrs.PlateCarree()\n",
    "\n",
    "    mask_TEMPO = (lat != fv_geo)&(lon != fv_geo)&(uvai != uvai_fv)\n",
    "    lon1D = lon[mask_TEMPO]\n",
    "    lat1D = lat[mask_TEMPO]\n",
    "    uvai1D = uvai[mask_TEMPO]\n",
    "\n",
    "    ax1 = fig.add_subplot(132, projection=proj)\n",
    "    ax1.set_extent([min_TEMPO_lon, max_TEMPO_lon, min_TEMPO_lat, max_TEMPO_lat], crs=transform)\n",
    "    im1 = ax1.scatter(lon1D, lat1D, c=uvai1D, s=1, cmap=plt.cm.jet\\\n",
    "                    , vmin=-4., vmax=4., transform=transform)\n",
    "    ax1.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "    gl = ax1.gridlines(draw_labels=True, dms=True)\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    cb1 = plt.colorbar(im1, ticks=[-4, -2, 0, 2, 4], fraction=0.022, pad=0.01)\n",
    "    cb1.set_label('UVAI', fontsize=10)\n",
    "    ax1.set_title('UVAI '+Tfname, size = 10)\n",
    "\n",
    "    ax2 = fig.add_subplot(133, projection=proj)\n",
    "    ax2.set_extent([min_TEMPO_lon, max_TEMPO_lon, min_TEMPO_lat, max_TEMPO_lat], crs=transform)\n",
    "    im2 = ax2.scatter(pp[valid_mask, 0], pp[valid_mask, 1]\\\n",
    "                    , c=DSCOVR_TEMPO_uvai[valid_mask], s=1, cmap=plt.cm.jet\\\n",
    "                    , vmin=-4., vmax=4., transform=transform)\n",
    "    ax2.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "    gl = ax2.gridlines(draw_labels=True, dms=True)\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    cb2 = plt.colorbar(im2, ticks=[-4, -2, 0, 2, 4], fraction=0.022, pad=0.01)\n",
    "    cb2.set_label('UVAI', fontsize=10)\n",
    "    ax2.set_title('DSCOVR EPIC UVAI re-mapped', size = 10)\n",
    "\n",
    "    ax3 = fig.add_subplot(131, projection=proj)\n",
    "    ax3.set_extent([min_TEMPO_lon, max_TEMPO_lon, min_TEMPO_lat, max_TEMPO_lat], crs=transform)\n",
    "    im3 = ax3.scatter(lon1D_DSCOVR_TEMPO, lat1D_DSCOVR_TEMPO, c=uvai1D_DSCOVR_TEMPO, s=1, cmap=plt.cm.jet\\\n",
    "                    , vmin=-4., vmax=4., transform=transform)\n",
    "    ax3.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "    gl = ax3.gridlines(draw_labels=True, dms=True)\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    cb3 = plt.colorbar(im3, ticks=[-4, -2, 0, 2, 4], fraction=0.022, pad=0.01)\n",
    "    cb3.set_label('UVAI', fontsize=10)\n",
    "    ax3.set_title('UVAI '+Dfname, size = 10)\n",
    "\n",
    "    plt.savefig('UVAI_'+Tfname+'.png', dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48326a76-8b82-4bb1-a532-60b3bc06c60f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
